#!/usr/bin/python
# script to take the tokenized output of a LightSpeed Pascal (LSP) file,
# typically as generated by lspTokenizer.py, and, based on a Pascal grammar,
# emit a parse tree, in JSON format.

import fileinput
import json
import sys
from tokens import *


class LSPSyntaxError(Exception):
    def __init__(self, expected, received):
        self.expected = expected
        self.received = received
        self.value = 'Syntax Error: expected "{0}", got "{1}" ({2})'.format(expected, received.name, received.data)


    def __str__(self):
        return repr(self.value)


def tokenGenerator():
    for line in fileinput.input():
        try:
            tuple = json.loads(line)
            print 'read token', tuple[0], 'name', tuple[1], 'data', tuple[2]
            token = { 'id': tuple[0], 'name': tuple[1], 'data': tuple[2] }
            yield token
        except Exception as e:
            print e


def getToken():
    global gTokens
    return next(gTokens)


def skipSpace():
    while True:
        token = getToken()
        code = token['id']
        if code != TOKEN_SPACE and code != TOKEN_NEWLINE:
            return token


def require(token, code, name):
    if token['id'] != code:
        raise LSPSyntaxError(name, token);


def parseUses():
    units = []
    while True:
        token = skipSpace()
        if token['id'] == TOKEN_IDENTIFIER:
            units.append(token['data'])
            token = skipSpace()
            if token['id'] == TOKEN_SEMICOLON:
                return { 'uses': units }
            require(token, TOKEN_COMMA, ',')
        else:
            raise LSPSyntaxError('uses list element', token)


def parseInterface():
    interface = []
    token = skipSpace()
    if token['id'] == TOKEN_USES:
        interface.append(parseUses())
    return { 'interface': interface }


def parseUnit(token):
    print 'parsing unit'
    unit_name = token['data']
    token = skipSpace()
    require(token, TOKEN_SEMICOLON, ';')
    token = skipSpace()
    require(token, TOKEN_INTERFACE, 'interface')
    interface = parseInterface()
    return { 'unit': { 'name': unit_name, 'body': [ interface ] } }


def parseFile():
    print 'parsing file'
    token = getToken()
    if token['id'] == TOKEN_UNIT:
        return parseUnit(token)
    else:
        raise LSPSyntaxError('unit', token)


# main program
gTokens = tokenGenerator()
tree = parseFile()
print '---', 'Parse Tree', '---'
print json.dumps(tree, indent=2, separators=(',', ': '))

